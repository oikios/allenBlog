#From Idea To an AR App
**分享嘉宾-Roc Zhang**
![Roc Zhang](media/15351948905164/Screen%20Shot%202018-08-25%20at%209.59.37%20PM.png)
Roc Zhang，本名张鹏，曾在MoreTech实习，现在流利说担任iOS研发。自己已有多款App上架app store，Adonis、Mr.Weather、Year Timer，去美国参加了这次WWDC2018。经验丰富，非常优秀。个人博客：https://www.roczhang.com/, 微博：[@RocZhang](https://weibo.com/u/3210801545)。Roc此次详细的介绍了ARKit的新特性以及他自己正在尝试的一个项目。

Roc分四部分向大家进行介绍

##WWDC 2018

首先Roc带来了这次WWDC 2018的亲身见闻。**AR is the future!**
![WWDC 2018](media/15351948905164/FromIdeaToAnARApp.jpg)
根据应用情报公司Sensor Tower提供的新数据，自从2017年9月19日发布iOS 11以来，已经下载了超过1300万个使用苹果ARKit构建的增强现实应用。

##ARKit
* ARKit 是一个移动端 AR 平台，用于在 iOS 上开发增强现实 app。
* ARKit 提供了接口简单的高级 API，有一系列强大的功能。
* 但更重要的是，它也会在目前的数千万台 iOS 设备上推出。为了获得 ARKit 的完整功能，需要 A9 及以上芯片。其实也就是大部分运行 iOS 11 的设备，包括 iPhone 6S。

###1.功能

####追踪（Tracking）

追踪是 ARKit 的核心功能，也就是可以实时追踪设备。
* 世界追踪（world tracking）可以提供设备在物理环境中的相对位置。
* 借助视觉惯性里程计Visual–Inertial Odometry(VIO)，可以提供设备所在位置的精确视图以及设备朝向，视觉惯性里程计使用了相机图像和设备的运动数据。
* iPhone X独有的人脸追踪

####场景理解（Scene Understanding）

追踪上面一层是场景理解，即确定设备周围环境的属性或特征。
* 平面检测（plane detection）
    平面检测能够确定物理环境中的表面或平面。例如地板或桌子。
* 命中测试（hit test）
    为了放置虚拟物体，Apple 还提供了命中测试功能。此功能可获得与真实世界拓扑的相交点，以便在物理世界中放置虚拟物体。
* 光线估算（Lighting Conditions）
    光线估算用于正确光照你的虚拟几何体，使其与物理世界相匹配

####渲染（Rendering）

结合使用上述功能，可以将虚拟内容无缝整合进物理环境。所以 ARKit 的最后一层就是渲染。
* Apple 让我们可以轻易整合任意渲染程序。他们提供的持续相机图像流、追踪信息以及场景理解都可以被导入任意渲染程序中。
* 对于使用 SceneKit 或 SpriteKit 的人，Apple 提供了自定义 AR view，替你完成了大部分的渲染。所以真的很容易上手。
* 同时对于做自定义渲染的人，Apple 通过 Xcode 提供了一个 metal 模板，可以把 ARKit 整合进你的自定义渲染器。
* Unity 和 UNREAL 会支持 ARKit 的全部功能

####2.ARKit历程

* 2017年，苹果在WWDC 2017大会上推出ARKit 1.0版本。
* 2018年初，伴随着iOS11.3的发布，ARKit 1.5版本推出。
    * 支持2D的图像检测，将真实世界的图像集成到AR体验中；
    * 支持虚拟对象放置在垂直表面；
    * 支持自动对焦，从而获得更清晰的视图
* WWDC 2018 ARKit 2.0横空出世，带来了一些新特性。
    * 加载和保存地图，提供了全新的持久化及多人体验
    * 环境纹理，可以更真实地渲染 AR 场景
    * 图像追踪，实时追踪 2D 图片
    * 物体检测，检测场景中的 3D 物体
    * 面部追踪提升

##SwiftShot

接下来Roc为大家带来了一款WWDC18上的游戏。
![SwiftShot_1](media/15351948905164/SwiftShot_1%20copy.jpg)

![SwiftShot_2](media/15351948905164/SwiftShot_2%20copy.jpg)

这个游戏体现了ARKit2的什么特性呢？
* 多用户体验。SwiftShot使用**MultipeerConnectivity**框架与其他本地玩家建立连接，并在设备之间发送游戏数据。
* 当你开始自己的会话时，开始会话的玩家会创建一个**ARWorldMap**，它包含ARKit对游戏板周围区域的空间理解。
* 其他参与的玩家会收到地图的副本，并看到一张主人游戏台的照片。移动他们的设备，帮助ARKit处理接收到的地图，并建立多人游戏的**共享参考框架**。

##How to Create an ARKit App –– Roc's idea

接下来Roc通过自己的项目想法向大家介绍了如何去创建一个ARKit应用。
![ARKit](media/15351948905164/ARKit.jpg)

![ARFrame](media/15351948905164/ARFrame.jpg)

ARKit 是基于 session 的 API。所以首先你要做创建一个简单的 ARSession。ARSession 对象用于控制所有处理流程，这些流程用于创建增强现实 app。但首先需要确定增强现实 app 将会做哪种类型的追踪。所以，还要创建一个 ARSessionConfiguration。ARSessionConfiguration 及其子类用于确定 session 将会运行什么样的追踪。只要设置好对应的属性，就可以获得不同类型的场景理解，并让 ARSession 做不同的处理。

要运行 session，只要对 ARSession 调用 run 方法即可，带上所需的 configuration。
run(_ configuration)
然后处理流程就会立刻开始。同时底层也会开始捕捉信息。幕后会自动创建 AVCaptureSession 和 CMMotionManager。它们用于获取图像数据和运动数据，这些数据会被用于追踪。

处理完成后，ARSession 会输出 ARFrames。

ARFrame 就是当前时刻的快照，包括 session 的所有状态，所有渲染增强现实场景所需的信息。要访问 ARFrame，只要获取 ARSession 的 currentFrame 属性。或者也可以把自己设置为 delegate，接收新的 ARFrame。

**代码实现**
```swift
class ViewController: UIViewController { 
...
@IBOutlet var sceneView: ARSCNView!
overide func viewDidLoad() { 
...
let scene = SCNScene(named: “xxx”)
sceneView.scene = scene }
override func viewWillAppear(_ animated: Bool) { 
...
let configuration = ARWorldTrachingConfiguration() Configuration.planeDetection = .horizontal
sceneView.session.run(configuration) }
}
```

###场景理解（Scene Understanding）

####平面检测

* 平面检测可以提供相对于重力的水平面。包括地面以及类似桌子等平行平面。ARKit 1.5 开始也支持了垂直平面检测。
* ARKit会在后台聚合多个帧的信息，所以当用户绕着场景移动设备时，它会掌握更多有关平面的信息。
* 平面检测还能校准平面的边缘，即在平面所有检测到的部分四周套上一个矩形，并将其与主要区域对齐。所以从中也能得知物理平面的主要角度。
* 如果同一个物理平面检测到了多个虚拟平面，ARKit会负责合并它们。组合后的平面会扩大至二者范围，因此后检测的那些平面就会从session中移除。

**代码实现**
```
// 创建新的 world tracking configuration
let configuration = ARWorldTrackingSessionConfiguration()

// 启用平面检测
configuration.planeDetection = .horizontal

// 改变运行中 session 的 configuration
mySession.run(configuration) 
```

####命中测试（hit test）

* 命中测试就是从设备发送一条光线，并与真实世界相交并找到相交点。
* ARKit 会使用所有能用的场景信息，包括所有检测到的平面以及3D特征点，这些信息都被 ARWorldTracking 用于确定位置。
* ARKit 然后发射光与所有能用的场景信息相交，然后用数组返回所有相交点，以距离升序排序。所以该数组的第一个元素就是离摄像头最近的相交点。
* 有不同的相交方式。可以通过 hit-test type 来定义。一共有四种方式。
    * Existing plane using extent: 如果在运行平面检测，并且 ARKit 已在环境中检测到了某个平面，就可以利用此平面。但你可以选择使用平面的范围或忽视它的范围。也就是说，例如你想让用户在某个平面上移动对象，就应该考虑范围，所以若光在范围内相交，就会产生一个相交点。如果这束光打到了范围的外面，就不会产生相交点。
    * Existing plane: 但如果你只检测到了地面的一小部分，但希望来回移动家具，就可以选择忽略范围，把当前平面当做无限平面。在这种情况下，你总是会获得相交点。
    * Estimated plane: 如果没有在运行平面检测或者还没有检测到某个平面，也可以根据目前的 3D 特征点来估算平面。在这种情况下，ARKit 会寻找环境中的处于共同平面的点并为它们安装一个平面。随后也返回与此平面的相交点。
    * Feature point: 如果你想在某个很小的表面上放东西，但此表面无法生成平面，或者是某个非常不规则的环境，也可以选择直接和特征点相交。也就是说光线会与特征点产生相交点，并将距离最近的特征点其作为结果返回。

**代码实现**

```
if let point = sceneView.hitTest(screenCenter, type: [.estimatedHorizontalPlane]).first { 
// Creat ARAnchor using result 

}
```

###一些手势

我们可以添加一些手势，来控制物体的缩放，旋转和移动。
![gesture](media/15351948905164/gesture.jpg)

###多用户操作 Multiuser

* 捕获AR World Map
![captureARWorldMap](media/15351948905164/captureARWorldMap.jpg)

* 捕获并发送AR World Map  ARKit提供了一个worldMappingStatus值：notAvailable，extending，limited，mapped，该值指示当前是否是捕获世界地图的好时机
![worldMappingStatus](media/15351948905164/worldMappingStatus.jpg)

* 接收当前世界地图
![getCurrentWorldMap](media/15351948905164/getCurrentWorldMap.jpg)

* 通过MultipeerConnectivity链接
![MultipeerConnectivity](media/15351948905164/MultipeerConnectivity.jpg)

* 接收并重新定位到共享地图
![Receive-Relocalized](media/15351948905164/Receive-Relocalized.jpg)

###Beat PM
![beatP](media/15351948905164/beatPM.jpg)
这是Roc正在构思的一个小游戏，可以在繁忙的工作中放松身心。相信不久就会呈现在大家面前，让我们拭目以待。

###MultipeerConnectivity&Peertalk
最后Roc又延伸介绍了下MultipeerConnectivity以及Peertalk（An iOS and Mac Cocoa library for communicating over USB），感兴趣的童鞋可以详细了解下。
![MultipeerConnectivity1](media/15351948905164/MultipeerConnectivity1.jpg)

![peerTalk](media/15351948905164/peerTalk.jpg)

##总结
Roc此次分享主要为大家介绍了ARKit的特性，以及如何使用ARKit。
1. ARKit提供的世界追踪功能可以提供设备在物理环境中的相对位置，场景理解可以确定设备周围环境的属性或特征，更好的在现实世界中放置物体。ARKit可以与SceneKit和SprintKit无缝集成。同时苹果提供了Metal模板，可以帮助开发者自定制渲染引擎。ARKit还提供多人操作功能，可以让多个人共同参与到游戏中来。

2. 如何使用ARKit，概括起来就是，ARSCNView 结合 SCNScene 中的虚拟世界信息和 ARsession 捕捉到的现实世界信息，渲染出 AR 世界。ARSessionConfiguration 及其子类指导 ARSession 如何追踪世界，追踪的结果以 ARFrame 返回。ARFrame 中的 ANAnchor 信息为 SceneKit 中的 SCNNode 提供了一些放置的点，以便将虚拟节点和现实锚点绑定。

##参考
https://xiaozhuanlan.com/topic/9061438725
https://developer.apple.com/videos/play/wwdc2017/602/
https://juejin.im/post/5a308ba96fb9a0450167f097
https://developer.apple.com/documentation/arkit
https://toutiao.io/posts/g54ix5/preview
https://developer.apple.com/documentation/arkit/swiftshot_creating_a_game_for_augmented_reality

